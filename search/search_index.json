{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Nodos","text":"<p>Welcome to the official documentation for Nodos, an advanced node-based graph scheduling system.</p> <p>Use the navigation on the left to browse through the different sections of the documentation.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Download the latest build as a .zip file here (version 1.3.0.b3519) </p> <p>Extract the file and run Nodos.exe to see the Editor</p> <p></p> <p>Now let's add 2 unsigned integer numbers and use Show Status node to display it on the NodeGraph.</p> <p>Right-click on node graph to display node list, create Thread and Sink nodes to execute your graphs and then you're ready for your journey!</p> <p></p>"},{"location":"#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Windows 10 or later</li> <li>GPU: The GPU driver should be supporting Vulkan 1.2 specs.</li> <li>Development Environment: C++ compiler (e.g., MSVC), Shader compiler (for GLSL/HLSL)</li> <li>Dependencies: Standard C++ libraries, Shader compilation tools</li> </ul>"},{"location":"#license","title":"License","text":"<p>Nodos is distributed under a custom license that is very permissive, even for commercial use. For detailed information, please refer to the LICENSE file included with the distribution.</p>"},{"location":"contributing/","title":"Contributing Guidelines","text":"<p>We encourage users to read the source code of our modules to understand the underlying mechanisms. If you find a bug or have suggestions for improvements, please contribute by submitting a pull request with your proposed fix.</p> <p>To contribute:</p> <ol> <li>Clone the Repository: Clone the official Nodos repository to your local machine.</li> <li>Create a Branch: Develop your fix or feature in a new branch.</li> <li>Submit a Pull Request: Once your changes are complete, submit a pull request for review.</li> </ol> <p>Please refer to the contributing guidelines in the repository for more details.</p>"},{"location":"installation/","title":"Installation Instructions","text":""},{"location":"installation/#developing-nodes-with-c","title":"Developing Nodes with C++","text":"<ol> <li>Set Up Environment: Ensure your development environment is configured with a C++ compiler and shader compilation tools.</li> <li>Install Dependencies with Command-Line Interface:<ul> <li>Open a terminal or command prompt in the Nodos directory.</li> <li>Run <code>nodos install</code> to handle any subsystem and dependency installation.</li> </ul> </li> <li>Verify Installation: Open a terminal or command prompt and run <code>nodos --version</code> to verify the installation.</li> </ol> <p>Info</p> <p>Just type <code>nodos</code> from command line to get help: </p>"},{"location":"introduction/","title":"Introduction","text":"<p>Nodos is an advanced node-based graph scheduling system that is designed to simplify and streamline the development process. The name \"Nodos\" humorously plays on the idea that it is \"not DOS,\" referencing the classic MS-DOS, while also emphasizing its core functionality as a node-oriented system.</p> <p></p> <p>Developed in C++, Nodos provides robust support for node creation using a C API. Additionally, it integrates seamlessly with shader languages such as GLSL and HLSL, enabling the compilation and runtime linking of shaders to shader parameters without the need for additional programming. This unique capability allows developers to execute C++ code and shaders within the node graph effortlessly, enhancing productivity and flexibility.</p> <p>Nodos also allows you to connect from another process to the Nodos process via cross-platform communication using the app SDK we provide. This means that even your external processes can be represented as nodes inside Nodos, enabling us to schedule and manage these processes within our comprehensive \"Uber\" node graph.</p>"},{"location":"introduction/#key-benefits-features","title":"Key Benefits &amp; Features","text":"<ul> <li>Simplified Development: By leveraging node-based graph scheduling, Nodos offers efficient scheduling and simplifies the complexity of managing various tasks and processes.</li> <li>Performance and Flexibility: C++ development ensures high performance, while the C API support and shader integration offer flexibility for a wide range of applications.</li> <li>Shader Integration: Automatic handling of GLSL&amp;HLSL shader compilation and runtime linking allows for seamless execution of graphical applications without additional C++ coding. Both fragment and computer shaders are supported.</li> <li>Cross Process Communication: Nodos allows you to connect from another process to the Nodos process via a cross-platform communication mechanism using the provided app SDK. This enables even external processes to be presented as nodes within Nodos.</li> <li>Uber Node Graph: With the ability to integrate external processes as nodes, Nodos can schedule and manage these processes within its comprehensive node graph, creating an \"Uber\" node graph that encompasses a wide array of tasks and operations.</li> <li>AI Model Support with ONNX Runtime: Run AI models in real-time using ONNX Runtime with CUDA and TensorRT, supporting image-to-image models including segmentation, super resolution, and depth generation.</li> </ul>"},{"location":"introduction/#example-applications","title":"Example Applications","text":"<p>Nodos provides example applications to demonstrate cross-process communication:</p> <ul> <li>Vulkan Application: Demonstrates high-performance graphics integration using the Vulkan Graphics API.</li> <li> <p>DirectX 12 Application: Demonstrates high-performance graphics integration using DirectX Graphics API.</p> </li> <li> <p>Unreal Engine 5 Integration: Nodos currently supports cross-process communication infrastructure for Unreal Engine 5. We provide an Unreal Engine 5 plugin named Nodos Link: github.com/mediaz/ue5plugin, available in our GitHub workspace. The source code for this plugin is publicly accessible, allowing developers to integrate and extend their Unreal Engine projects with Nodos seamlessly.</p> </li> </ul>"},{"location":"introduction/#use-cases","title":"Use Cases","text":"<p>Nodos can be utilized in various domains, including but not limited to:</p> <ul> <li>Real-Time Rendering: Using Vulkan, rendering nodes and image filters or compute shader nodes can be developed.</li> <li>Real-Time AI Processing With AI subsystem, ONNX models can be loaded and run in real-time, to process images/video. Such as segmentation, detection, depth generation, super resolution etc...</li> <li>Distributed Systems: Facilitates the integration and management of distributed processes, presenting them as nodes in a unified graph. Since Nodos provides a lot of capabilities in terms of video I/O, rendering, image filters and AI capabilities; your application can benefit from all these capabilities via just getting linked with Nodos AppSDK.</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<ul> <li>Discord Server: Join the Nodos Community Discord server for support from other users and developers.</li> </ul>"},{"location":"development/","title":"General Info","text":"<p>Nodos is a very large developing platform, so we use several 3rd-party libraries and built some standards on top of them. These are important for developers that'll use C/C++ APIs of Nodos.</p>"},{"location":"development/#flatbuffers","title":"Flatbuffers","text":"<p>Our cross-process communication is based on Google's gRPC and flatbuffers. We represent nodes, pins and their data types with flatbuffers. So you should use flatbuffers to create your own data types. For this purpose, you're gonna use built-in flatbuffers types.</p>"},{"location":"development/#built-in-data-types","title":"Built-in data types","text":"<p>Flatbuffers already has built-in types (such as <code>float</code>, <code>uint</code> etc), but we define the types below on top of them because they're used frequently by developers:</p> flatbuffers type C++ type float float double double ubyte uint8_t ushort uint16_t uint uint32_t ulong uint64_t byte int8_t short int16_t int int32_t long int64_t vec2 <code>{float x,y;}</code> vec2d <code>{double x,y;}</code> vec2i <code>{int x,y;}</code> vec2u <code>{uint32_t x,y;}</code> vec3 <code>{float x,y,z;}</code> vec3d <code>{double x,y,z;}</code> vec3i <code>{int x,y,z;}</code> vec3u <code>{uint32_t x,y,z;}</code> vec4 <code>{float x,y,z,w;}</code> vec4d <code>{double x,y,z,w;}</code> vec4i <code>{int x,y,z,w;}</code> vec4u <code>{uint32_t x,y,z,w;}</code> vec4u8 <code>{uint8_t x,y,z,w;}</code> void void StringList <code>{string name; vector&lt;string&gt; list;}</code> <p>There are many more built-in types but they're mostly built on top these with some enums so we recommend you to investigate it yourself in <code>SDK/types/Builtins.fbs</code> file.</p>"},{"location":"development/plugins/","title":"Plugins","text":"<p>A Nodos plugin defines nodes and their behaviors, and pin data types. Nodos loads plugins dynamically and makes its nodes and data types available to be used in the node graph to perform tasks.</p> <p>Nodos Package Manager CLI tool (<code>nodos</code>) has a command <code>create plugin</code> that can generate a simple plugin for Nodos. You can use <code>nodos create --help</code> for detailed information about the command.</p>"},{"location":"development/plugins/#create-a-plugin","title":"Create a plugin","text":"<p>Let's create our first Nodos plugin with command below.</p> <pre><code>nodos create plugin mycorp.myplugin\n</code></pre> <p>It will output: <pre><code>Creating a new Nodos module project of type Plugin\nPlugin project created at \"./Module/mycorp.myplugin\"\nFound 1 modules in C:/Nodos/Module/mycorp.myplugin\n</code></pre></p> <p>This will create a folder named <code>mycorp.myplugin</code> under <code>Module</code> folder of Nodos Workspace (where <code>nodos</code> tool resides) with folder structure as below.</p> <pre><code>./Module/mycorp.myplugin/\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 Source\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 PluginMain.cpp\n\u2514\u2500\u2500 mycorp.myplugin.noscfg\n</code></pre> <p>This folder contains a CMake project file, a C++ source file with minimal code and a Nodos plugin manifest file <code>.noscfg</code>.</p>"},{"location":"development/plugins/#building","title":"Building","text":"<p>Now generate CMake project using our CMake helpers, which can be found in <code>Toolchain/CMake</code> folder of Nodos Workspace and build it using commands run from workspace root:</p> <pre><code># This will scan 'Module' folder and generate project files.\ncmake -S Toolchain/CMake -B Project\n</code></pre> <pre><code>cmake --build Project\n</code></pre> <p>This will result in a DLL file under <code>Module/mycorp.myplugin/Binaries</code> folder, and Nodos will be able to load this plugin.</p>"},{"location":"development/plugins/#loading-a-plugin","title":"Loading a plugin","text":"<p>Open the editor and click Fetch button of Modules pane. This will scan the plugin and show it under uncategorized table on Plugins section. Click on the plugin and you'll see Load button at the bottom. </p> <p>Info</p> <p>A plugin should implement <code>nosImportDependencies</code>, <code>nosExportPlugin</code> &amp; <code>nosGetPluginAPIVersion</code> functions in Nodos C API for plugins (defined under <code>Engine/&lt;version&gt;/SDK/include/PluginAPI.h</code>).</p>"},{"location":"development/plugins/#defining-a-node","title":"Defining a node","text":"<p>For simplicity, tutorial will be based on our C++ helpers. Create a struct <code>PluginExtension</code> that is derived from nos::PluginFunctions publicly and override <code>ExportNodeFunctions()</code> function.</p> <p>When a plugin is loaded, <code>ExportNodeFunctions()</code> is called twice by the engine. One for querying node count and another one for getting the node list. That means, your function should start something like,</p> <p><pre><code>*outSize = nodeSize;\nif(!outFunctions) \n    return NOS_RESULT_SUCCESS;\n</code></pre> and then start filling <code>nosNodeFunctions*</code> list.</p> <p>For each node you want to register, you can implement a class derived from <code>nos::NodeContext</code>. You should override the base class' functions you're going to use (<code>OnPinValueChanged()</code> for example).</p> Example C++ code  Registering a node that gets float from input pin and prints it on Log pane <pre><code>#include &lt;Nodos/PluginAPI.h&gt;\n#include &lt;Nodos/PluginHelpers.hpp&gt;\n#include &lt;Nodos/Helpers.hpp&gt;\n\nNOS_INIT() // Defines nosGetPluginAPIVersion\nNOS_BEGIN_IMPORT_DEPS() // Defines nosImportDependencies and makes nosEngineServices available as 'nosEngine'.\n    // If you have dependencies, you can define them here like\n    // NOS_IMPORT_DEP(\"mycorp.somedep\", \"1.0.0\"...)\nNOS_END_IMPORT_DEPS()\n\nstruct PrintLogPaneNodeContext : nos::NodeContext\n{\n    PrintLogPaneNodeContext(const nosFbNode* node) : nos::NodeContext(node)\n    {\n    }\n\n    void OnPinValueChanged(nos::Name pinName, nosUUID pinId, nosBuffer value) override\n    {\n        if (pinName == NOS_NAME_STATIC(\"Message\"))\n        {\n            auto* floatInfo = nos::InterpretPinValue&lt;float&gt;(value);\n            nosEngine.LogI(std::to_string(*floatInfo).c_str());\n        }\n    }\n};\n\nnosResult RegisterPrintLogPaneNode(nosNodeFunctions* outFunctions)\n{\n    NOS_BIND_NODE_CLASS(NOS_NAME(\"mycorp.myplugin.PrintLog\"), \n        PrintLogPaneNodeContext, \n        outFunctions)\n    return NOS_RESULT_SUCCESS;\n}\n\nstruct PluginExtension : public nos::PluginFunctions\n{\n    virtual nosResult ExportNodeFunctions(size_t&amp; outSize, nosNodeFunctions** outFunctions) override\n    {\n        outSize = 1;\n        if (!outFunctions)\n            return NOS_RESULT_SUCCESS;\n\n        NOS_RETURN_ON_FAILURE(RegisterPrintLogPaneNode(outFunctions[0]));\n        return NOS_RESULT_SUCCESS;\n    }\n};\n\nNOS_EXPORT_PLUGIN_FUNCTIONS(PluginExtension);\n</code></pre> <p>If you build the plugin and try to load it from the engine, you'll get \"Plugin is trying to register a node that doesn't exist in its node definitions\" error. This is because Nodos reads node configuration (.noscfg) and node definition (.nosdef) files to create node properties.</p> <p>Configuration file describes the whole plugin such as; compiled binary path, node definition file paths, plugin's dependencies to subsystems and other plugins, custom data types (flatbuffers based).</p> <p>To add a node, create a .nosdef file. It should have JSON schema. You can define multiple nodes in one .nosdef file.</p> <p>Each node should have a class name, display name, content type (either a job that has no sub-nodes or a graph that has sub-graphs), user-friendly description text, pins &amp; functions.</p> <p>We're gonna use only a single pin today, so we don't need to define functions. After describing your nodes in the related .nosdef files, you should associate them with the plugin in .noscfg's <code>associated_nodes</code> list.</p> Example .noscfg &amp; .nosdef files  Registering a node that gets float from input pin and prints it on Log pane .nosdef <pre><code>{\n    \"nodes\":[\n        {\n            \"class_name\": \"PrintLog\",\n            \"display_name\": \"Test to Log\",\n            \"contents_type\": \"Job\",\n            \"description\": \"Prints the inputted float into log\",\n            \"pins\": [\n                {\n                    \"name\": \"Message\",\n                    \"type_name\": \"float\",\n                    \"show_as\": \"INPUT_PIN\",\n                    \"can_show_as\": \"INPUT_PIN_ONLY\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre> .noscfg <pre><code>{\n    \"info\": {\n        \"id\": {\n            \"name\": \"mycorp.myplugin\",\n            \"version\": \"0.1.0\"\n        },\n        \"display_name\": \"mycorp.myplugin\",\n        \"description\": \"\",\n        \"dependencies\": []\n    },\n    \"binary_path\": \"./Binaries/mycorp.myplugin\",\n    \"node_definitions\": [\n        \"PrintLog.nosdef\"\n    ],\n    \"defaults\": [],\n    \"custom_types\": [],\n    \"associated_nodes\": [\n        {\n            \"category\": \"Sample\",\n            \"class_name\": \"PrintLog\",\n            \"display_name\": \"Print Log\"\n        }\n    ]\n}\n</code></pre> <p>Now you should be able to see your first node in the node graph. In examples above, we created a node that prints to Log pane only if the pin's value changes. So create an Add node and sets its input values. After you connect it to the Message pin, <code>OnPinValueChanged()</code> will be called and it will print the value. Everytime you change the pin's value by changing output value of the connection, it'll be printed.</p>"},{"location":"development/plugins/#using-nodos-cli-to-add-a-pin","title":"Using nodos CLI to add a pin","text":"<p>You can use <code>nodos pin</code> command to add a pin to a node in the workspace. If not all parameters are provided, it will enter interactive mode.</p> <p><pre><code>nodos pin mycorp.myplugin.PrintLog SomeNewPin\n</code></pre> Because we didn't provide <code>--show-as</code> parameter, it will ask for it. This is used to define the pin's current kind in the node. It can be an input pin, output pin or a property.</p> <pre><code>? Select pin show-as:\n&gt; INPUT_PIN\n  OUTPUT_PIN\n  PROPERTY\n[\u2191\u2193 to move, enter to select, type to filter]\n</code></pre> <p>After this, it will ask for the <code>can-show-as</code> parameter. This is used to define which show-as options are available for the pin.</p> <p><pre><code>? Select pin can-show-as:\n  [x] INPUT_PIN\n  [ ] OUTPUT_PIN\n&gt; [x] PROPERTY\n[\u2191\u2193 to move, space to select one, \u2192 to all, \u2190 to none, type to filter]\n</code></pre> Here we selected <code>INPUT_PIN</code> and <code>PROPERTY</code> as the options. You can select multiple options by pressing space. This creates the possibility for this pin to be changed to a property in the editor by the end user.</p> <p>After this, it will ask for the <code>type-name</code> parameter. This parameter is used to define the data type of the pin.</p> <pre><code>? Enter pin type name for pin: float\n</code></pre> <p>You can use <code>nodos pin --help</code> for detailed information about the command.</p>"},{"location":"development/process/","title":"Application Development","text":"<p>This page is for users that already have an application and want it to communicate with Nodos engine as a node. With this way, users can make changes on their applications using Nodos Editor.</p> <p>When an application is connected to engine, engine creates a node for it. Application is free to modify this node but can't add another node. This means, an application can have only one node inside of an engine instance.</p> <p>Let's create an example console application that gets a float input from Nodos and prints it on the console.</p>"},{"location":"development/process/#check-your-nodos-appsdk-version","title":"Check your Nodos AppSDK version","text":"<p>Nodos is a evolving project, so its AppSDKs. This means, there can be version compatibility issues between your applications and Nodos. To solve this, AppSDK has its own version. You can see version of your downloaded engine's AppSDK as <code>process_sdk_version</code> in info.json file under your engine's SDK folder.</p> <p>Nodos also has a command to if the intended SDK version is compatible with current one. You can parse the output from command below in your build systems to check against incompatibility and find AppSDK's directory:</p> <p><code>nodos sdk-version &lt;intended_sdk_version_here&gt; process</code></p>"},{"location":"development/process/#include-nodos-appsdk-to-your-solution","title":"Include Nodos AppSDK to your solution","text":"<p>All header files you'll need from Nodos is under the <code>include</code> folder of AppSDK's directory (the path outputted from command above). So we recommend you to include it from your project settings.</p> <p>Our headers are written in C++20 standard, so you must move your project to C++20.</p>"},{"location":"development/process/#load-appsdk-dynamic-library-and-its-functions","title":"Load AppSDK dynamic library and its functions","text":"<p>Using your platform's dynamically linked shared object APIs, load nosAppSDK dynamic library to your application. After that, you must load the functions mentioned below (by using <code>GetProcAddress()</code> on Windows for example) and cast them to their related function types.</p>"},{"location":"development/process/#functionname-functiontype-table","title":"FunctionName-&gt;FunctionType table","text":"<p><code>CheckSDKCompatibility</code> cast to <code>nos::app::FN_CheckSDKCompatibility*</code></p> <p><code>MakeAppServiceClient</code> cast to <code>nos::app::FN_MakeAppServiceClient*</code></p> <p><code>ShutdownClient</code> cast to <code>nos::app::FN_ShutdownClient*</code></p>"},{"location":"development/process/#function-descriptions","title":"Function descriptions","text":"<p>CheckSDKCompatibility: Checks against version conflicts. Call this function with the version your headers define. If headers you included isn't compatible with the one that's dynamic library is compiled with, it fails.</p> <p>MakeAppServiceClient: Creates a <code>AppServiceClient</code> object that you can use access the gRPC. With this object, you can connect to any Nodos engine you want over network. We also use this object to register application event callbacks because our gRPC communication with apps are asynchronous.</p> <p>ShutdownClient: Delete all resources related to client. If you lost connection to Nodos (or want to disconnect), use this to clear any remaining data. Call this after unregistering delegates.</p>"},{"location":"development/process/#define-eventdelegates","title":"Define EventDelegates","text":"<p>As said above, our gRPC communication is asynchronous. We uses event delegation design pattern in Nodos to handle callbacks to applications. If you want to get notified about the changes made to your node on the graph (as you should, because there are no other ways to communicate with Nodos), you should implement it.</p> <p>Derive <code>nos::app::IEventDelegates</code> first.</p> <p>Define all pure virtual functions on derived class and create a object of it.</p> <p>Call <code>client-&gt;RegisterEventDelegates()</code> with the object. All this does is storing the object in nosAppSDK side to pass it to the Nodos instance automatically using gRPC when you connect to an instance.</p> <p>Info</p> <p>When you connect to Nodos, you can check which events called when. More information will be written later.</p>"},{"location":"development/process/#connect-to-a-nodos-instance","title":"Connect to a Nodos instance","text":"<p>You already defined the IP address and the port of your Nodos instance in <code>MakeAppServiceClient()</code> call. So run a Nodos instance with the specified address to be able to connect.</p> <p>Info</p> <p>If you want to connect to a Nodos that has different address, you gotta create another <code>AppServiceClient</code> object after destroying the one that already exist.</p> <p>Call <code>AppServiceClient::IsConnected()</code> to check your connection to Nodos instance.</p> <p>Call <code>AppServiceClient::TryConnect()</code> to try a connection.</p>"},{"location":"development/process/#use-the-appnode-in-nodegraph","title":"Use the AppNode in NodeGraph","text":"<p>You can see your application's name you defined while creating <code>AppServiceClient</code> object in Apps pane. If you drag and drop it to NodeGraph, <code>onNodeUpdated()</code> event will be called.</p> <p>After this, you are free to experiment with which events are called when. As this tutorial's main purpose is to teach you how you can connect to Nodos, this is enough. More information will be written later.</p>"},{"location":"development/process/#suggestions","title":"Suggestions","text":"<p>We recommend you to implement a TaskQueue-like structure to handle incoming event callbacks considering <code>FrameNumber</code> input passed. Otherwise, you might encounter synchronization issues because callbacks will be executed on a different thread than the main thread.</p> <p>Info</p> <p>You can look into our Vulkan and DirectX12 sample applications for more information. Both applications is organized like below:</p> <p>Create a window &amp; initialize the graphics API (note that Nodos has no DX12 backend)</p> <p>Wait for a connection to Nodos</p> <p>Add an input and an output pin to the application node</p> <p>Get the texture handle from input pin</p> <p>Render on top of it and present it on the application window</p> <p>Send the final rendered texture to Nodos using output pin.</p>"},{"location":"development/subsystems/","title":"Subsystems","text":"<p>Subsystems are fun!</p>"},{"location":"development/subsystems/nos.sys.vulkan/","title":"Vulkan Subsystem","text":"<p>Subsystem <code>nos.sys.vulkan</code> features an API for plugins to communicate with vulkan &amp; send commands to the GPU.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#minimal-example","title":"Minimal example","text":"<p>For a plugin or a subsystem, to define a dependency to nosVulkan, add the <code>nos.sys.vulkan</code> dependency in the noscfg file as shown in <code>Test.noscfg</code>. Then in the file that contains the <code>NOS_INIT</code> macro, include <code>&lt;nosVulkanSubsystem/nosVulkanSubsystem.h&gt;</code> for <code>nos.sys.vulkan</code> API, then in the <code>nosExportNodeFunctions</code> function request the Vulkan subsystem using <code>nosEngine.RequestSubsystem</code> function. Then <code>nosVulkan</code> global variable can be used anywhere to communicate with the <code>nos.sys.vulkan</code> API. <code>&lt;nosVulkanSubsystem/Helpers.hpp&gt;</code> contains helper functions and <code>&lt;nosVulkanSubsystem/Types_generated.h&gt;</code> contains flatbuffers headers for Texture.</p> Test.noscfg<pre><code>{\n    \"info\": {\n        \"id\": {\n            \"name\": \"nos.test\",\n            \"version\": \"1.0.0\"\n        },\n        \"display_name\": \"Test\",\n        \"description\": \"Test plugin.\",\n        \"dependencies\": [\n            {\n                \"name\": \"nos.sys.vulkan\",\n                \"version\": \"1.0.0\"\n            }\n        ]\n    },\n    \"node_definitions\":...\n}\n</code></pre> Test.cpp<pre><code>#include &lt;Nodos/PluginAPI.h&gt;\n\n#include &lt;nosVulkanSubsystem/nosVulkanSubsystem.h&gt;\n#include &lt;nosVulkanSubsystem/Helpers.hpp&gt;\n\nNOS_INIT();\nnosVulkanSubsystem* `nos.sys.vulkan` = nullptr;//`nos.sys.vulkan` is a variable that is declared as extern in nosVulkanSubsystem.h\nextern \"C\"\n{\n\n    NOSAPI_ATTR nosResult NOSAPI_CALL nosExportNodeFunctions(size_t* outCount, nosNodeFunctions** outFunctions)\n    {\n        *outCount = (size_t)(1);\n        if (!outFunctions)\n            return NOS_RESULT_SUCCESS;\n        auto ret = nosEngine.RequestSubsystem(NOS_NAME_STATIC(NOS_VULKAN_SUBSYSTEM_NAME), 1, 0, (void**)&amp;nosVulkan);\n        //System might not have nosVulkanSubsystem with the requested version, so be sure to check for it.\n        if (ret != NOS_RESULT_SUCCESS)\n            return ret;\n        //Register nodes etc...\n        outFunctions[0]-&gt;ClassName = NOS_NAME_STATIC(\"nos.test.CopyTestLicensed\");\n        outFunctions[0]-&gt;ExecuteNode = [](void* ctx, const nosNodeExecuteArgs* args)\n        {\n            nosCmd cmd;\n            nosVulkan-&gt;Begin(\"(nos.test.CopyTest) Copy\", &amp;cmd);\n            auto values = nos::GetPinValues(args);\n            nosResourceShareInfo input = nos::vkss::DeserializeTextureInfo(values[NOS_NAME_STATIC(\"Input\")]);\n            nosResourceShareInfo output = nos::vkss::DeserializeTextureInfo(values[NOS_NAME_STATIC(\"Output\")]);\n            nosVulkan-&gt;Copy(cmd, &amp;input, &amp;output, 0);\n            nosVulkan-&gt;End(cmd, NOS_FALSE);\n            return NOS_RESULT_SUCCESS;\n        };\n        return NOS_RESULT_SUCCESS;\n    }\n}\n</code></pre> <p>Warning</p> <p>Don't forget to check for the availability of the subsystem. Since the subsystem may not be available.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#shaders","title":"Shaders","text":""},{"location":"development/subsystems/nos.sys.vulkan/#compiling-registering","title":"Compiling &amp; Registering","text":"<p>There are 2 ways of compiling and registering a shader. One is by defining it in a Shader Only Node and another is by registering it in <code>registerXXX()</code> calls. To be able to execute shaders, a related <code>ShaderPass</code> should be created. Compute shaders should create <code>ComputePass</code>, fragment and vertex shader should create <code>RenderPass</code>. A <code>RenderPass</code> has to have a fragment shader but vertex shader is optional (if not specified, full quad vertex shader is used).</p>"},{"location":"development/subsystems/nos.sys.vulkan/#shader-only-nodes","title":"Shader Only Nodes","text":"<p>To add a shader only node(such as <code>Color Correct</code>), add the node to plugin's noscfg and create a nosdef for the node. In the nosdef, add pins and other fields as if the node is a regular node. Then, in the node definition, fill the <code>\"contents</code> field as shown in the example. The path given in <code>shader</code> field is relative to the plugin's noscfg file. If the file extension doesn't end with <code>.spv</code>, <code>nos.sys.vulkan</code> tries to compile the given file using glslc and dxc, whichever compiles. Shader only nodes do not need a .dll file and the plugin doesn't need to export their node functions. <pre><code>{\n    \"nodes\": [\n        {\n            \"class_name\": \"ColorCorrect\",\n            \"contents_type\": \"Job\",\n            \"contents\": {\n                \"type\": \"nos.sys.vulkan.GPUNode\",\n                \"options\": {\n                    \"shader\": \"../Shaders/ColorCorrect.hlsl\",\n                    \"stage\": \"FRAGMENT\"\n                }\n            },\n            \"pins\": ...\n        }\n    ]\n}\n</code></pre></p>"},{"location":"development/subsystems/nos.sys.vulkan/#registering-a-shader-or-a-gpu-pass","title":"Registering a shader or a GPU pass","text":"<p>To compile a shader, caller should provide either human-readable (either HLSL or GLSL) source file path, human-readable source file text, SPIR-V blob file path or SPIR-V blob data to <code>ShaderInfo2.Source</code>. To create a pass, a globally unique <code>PassName</code> and shaders should be provided. To create a RenderPass, fragment shader should be passed to <code>nosPassInfo.Shader</code> and vertex shader (optional) should be passed to <code>nosPassInfo.VertexShader</code>.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#types","title":"Types","text":""},{"location":"development/subsystems/nos.sys.vulkan/#nosresourcetype","title":"nosResourceType","text":"<p><pre><code>enum nosResourceType\n{\n    NOS_RESOURCE_TYPE_BUFFER = 1,\n    NOS_RESOURCE_TYPE_TEXTURE = 2,\n}\n</code></pre> Refer to nosResourceShareInfo.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#nosresourceinfo","title":"nosResourceInfo","text":"<p><pre><code>struct nosResourceInfo\n{\n    nosResourceType Type;\n    union {\n        nosTextureInfo Texture;\n        nosBufferInfo Buffer;\n    };\n};\n</code></pre> <code>Type</code> must be set to adequate <code>nosResourceType</code> based on which resource info is used.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#functions","title":"Functions","text":"<p>Most operations in <code>nos.sys.vulkan</code> API uses a <code>nosCmd</code> struct to record commands and most calls are not synchronized between CPU and GPU.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#begin","title":"Begin","text":"<p><code>nosResult Begin(const char* name, nosCmd* outCmd)</code> Parameters: <code>name</code>: Debug name for the commands that will be recorded using this cmd. <code>outCmd</code>: Filled with the handle for a command buffer that can be used with other calls.</p>"},{"location":"development/subsystems/nos.sys.vulkan/#end","title":"End","text":"<p><code>nosResult End(nosCmd cmd, nosBool forceSubmit);</code> Marks the end of command buffer's use. Parameters: <code>forceSubmit</code>: Submits the command buffer to the GPU. Recorded commands are not executed until the command buffer is submitted to the GPU, regular nodes in the node path can get away with not submitting the command buffer. Nodes that communicate between the CPU and the GPU or other graphics API's needs to submit the command buffer in appopriate points. Mind that submitting the command buffer has a significant performance hit. This does not wait for the GPU, refer to End2. Command buffers used outside of the Scheduler thread are submitted even if this parameter is false. </p>"},{"location":"development/subsystems/nos.sys.vulkan/#end2","title":"End2","text":"<p><code>nosResult End2(nosCmd cmd, nosBool forceSubmit, nosGPUEvent* outEventHandle);</code> Marks the end of command buffer's use. Parameters: <code>forceSubmit</code>: Submits the command buffer to the GPU. Command buffers used outside of the Scheduler thread are submitted even if this parameter is false. Refer to End for more detailed information. <code>outEventHandle</code>: If not null, fills the value with an event that will be signalled when the GPU completes execution of the commands in the command buffer. Mind that this does not submits the command buffer to GPU unless <code>forceSubmit</code> is <code>true</code>, waiting it before the command buffer is submitted will result in a timeout or deadlock. Returned event must be waited at some point using WaitGpuEvent, unless the event results in a leak.</p> <p><code>nosResult Copy(nosCmd, const nosResourceShareInfo* src, const nosResourceShareInfo* dst, const char* benchmark);</code></p> <p><code>nosResult RunPass(nosCmd, const nosRunPassParams* params);</code></p> <p><code>nosResult RunPass2(nosCmd, const nosRunPass2Params* params);</code></p> <p><code>nosResult RunComputePass(nosCmd, const nosRunComputePassParams* params);</code></p> <p><code>nosResult Clear(nosCmd, const nosResourceShareInfo* texture, nosVec4 color);</code></p> <p><code>nosResult Download(nosCmd, const nosResourceShareInfo* texture, nosResourceShareInfo* outBuffer);</code></p> <p><code>nosResult ImageLoad(nosCmd, const void* buf, nosVec2u extent, nosFormat format, nosResourceShareInfo* inOut);</code></p> <p><code>nosResult CreateResource(nosResourceShareInfo* inout);</code></p> <p><code>nosResult ImportResource(nosResourceShareInfo* inout);</code></p> <p><code>nosResult DestroyResource(const nosResourceShareInfo* resource);</code></p> <p><code>nosResult ReloadShaders(nosName nodeName);</code></p> <p><code>uint8_t* Map(const nosResourceShareInfo* buffer);</code></p> <p><code>nosResult GetColorTexture(nosVec4 color, nosResourceShareInfo* out);</code></p> <p><code>nosResult GetStockTexture(nosResourceShareInfo* out);</code></p> <p><code>nosResult CreateSemaphore(uint64_t pid, uint64_t externalOSHandle, nosSemaphore* outSemaphore);</code></p> <p><code>nosResult DestroySemaphore(nosSemaphore semaphore);</code></p> <p><code>nosResult AddSignalSemaphoreToCmd(nosCmd cmd, nosSemaphore semaphore, uint64_t signalValue);</code></p> <p><code>nosResult AddWaitSemaphoreToCmd(nosCmd cmd, nosSemaphore semaphore, uint64_t waitValue);</code></p> <p><code>nosResult SignalSemaphore(nosSemaphore semaphore, uint64_t value);</code></p> <p><code>nosResult RegisterShaders(size_t count, nosShaderInfo* shaders);</code></p> <p><code>nosResult RegisterPasses(size_t count, nosPassInfo* passInfos);</code></p>"},{"location":"development/subsystems/nos.sys.vulkan/#waitgpuevent","title":"WaitGpuEvent","text":"<p><code>nosResult WaitGpuEvent(nosGPUEvent* eventHandle, uint64_t timeoutNs);</code> Waits for the gpu to complete the work until the given event or timeout, then deletes the event. Parameters: <code>eventHandle</code>: Event handle to wait, will be set to null afterwards. <code>timeoutNs</code>: Timeout in nanoseconds, pass UINT64_T for max and 0 for deleting the event without any wait.</p>"},{"location":"usages/","title":"Instructions","text":"<ol> <li>Integrate Shaders: Write your shaders in GLSL or HLSL. Nodos will handle the compilation and runtime linking automatically.</li> <li>Build a Node Graph: Use the Nodos interface to connect and configure your nodes, creating the desired graph structure.</li> <li>Run the Graph: Execute the node graph within Nodos to see your code and shaders in action.</li> </ol>"},{"location":"usages/#integrate-shaders","title":"Integrate Shaders","text":""},{"location":"usages/#build-a-node-graph","title":"Build a Node Graph","text":"<p>You can find the nodes available in your engine by right-clicking on the node graph.</p>"},{"location":"usages/#run-the-graph","title":"Run the Graph","text":"<p>In Nodos, you have to handle the running thread's behaviour from the beginning. Execution of a set of nodes start from a Thread node and ends with a Sink node.</p> <p>There is also a Threaded Sink node to execute basic nodes</p>"},{"location":"usages/ai_models/","title":"Running AI Models","text":"<p>Nodos support both AI Model inference and optimization with TensorRT.  One could use AIModelLoader node, which can be found in ML-&gt;AI Models-&gt;AI MOdel Loader in the context menu with the right click. This node required the Model Path, which is path to any ONNX Model (with ONNXRuntime 1.16 supports).  </p> <p>For ONNXRunLocation, we suggest using TensorRT and enabling FP16 Optimization in general, but some models may not be suitable for TensorRT. In that case, model load will fail and you get the corresponding error log in the Log pane for the reasons of fail.</p> <p>Note that optimization may take some time, and for the AI Models with dynamic input/output (models where any dimension of the i/o tensors is -1), the optimization will be performed during the output tensor determination. In other words, when you first conenct an input to the model. During that time the node status message \"Determining Output Tensor Info...\" will be displayed.</p> <p>For more advanced and performant applications, the Stream pin would come handy; this provides full GPU async operation of the AI Model Inference pipeline for that specific stream. But you must set the Stream pin before clicking to \"LoadModel\" button.</p> <p>After loading the model, we can connect the Model pin to the ONNXRunner node to see the I/O information of the model.</p> <p></p> <p>In above figure one can observe that the loaded model has the Input Tensor called \"image\" with the shape (1, 3, -1, -1) and Output Tensor called \"depth\" with the dimensions (-1, 1, -1, -1).</p> <p>In general, the Output Tensor strictly depends on the Input Tensor and it will be determined when the Input Tensor set.</p> <p>Now lets discuss how we can create the image tensor within Nodos features.</p>"},{"location":"usages/ai_models/#texture-tensor-transformations","title":"Texture-Tensor Transformations","text":"<p>It is well known that TensorRT and CUDA are not compatible with Vulkan data by nature, but in Nodos this is not problem thanks to our Texture-to-Tensor and Tensor-to-Texture nodes.</p> <p>Users first must understand the nature of their tensor requested by the AI Model, this information is hidden in the \"element_type\" field of the Tensor Pins.</p> <p></p> <p>In the Figure above we see that the element type of the image tensor is \"float\", which corresponds to 32 bit per elements. So, we must ensure that the texture we want to use for our model is compatible with this data format. To do that, one can either use a texture with R32G32B32A32_SFLOAT type or make use of another handy Nodos feature: Texture Format Converter Node.</p> <p>First, lets create a Texture Format Converter Node and select the OutputFormat parameter as R32G32B32A32_SFLOAT.</p> <p></p> <p>Then create TextureToTensor node and connect the TextureFormatConverter's output to the TextureToTensor's input.</p> <p></p> <p>Now remember that the \"image\" input of the our AI Model was requesting a tensor with shape (1, 3, -1, -1), this also known as NCHW layout where the 1st dimension corresponds to Batch, 2nd dimension corresponds to Channel, 3rd dimension is Height and 4th dimension is Width.</p> <p>And also observe that our TextureToTensor node has NHWC Layout. Now lets change that to NCHW and also since our model requires 3 channel image also change the Output Format parameter of TextureToTensor to RGB from RGBA.</p> <p></p> <p>Observe that now the OutputTensor has the shape (1,3,1080,1920) and this shape is compatible with our AI Model's input.</p> <p>Now we can begin the TensorRT optimization (since we have dynamic input model) by connecting this tensor to our model.</p> <p></p> <p>After these steps, now we can connect the \"depth\" pin of our AI Model to TensorToTexture node with similar adjustments: choose the NCHW layout and since our output image has only one channel enable \"EnforceFourChannelOutput\".</p> <p></p> <p>Congratulations, now you can run any image-to-image AI model by following the same pipeline creation steps.</p>"},{"location":"usages/ai_models/#useful-features","title":"Useful Features","text":"<p>If you are a curious about the GPU run time of your model, in the ONNXRunner Node properties you simply can enable \"Measure Time\" to see how long it takes for your model to run in GPU, you can open the Watch pane and read the ONNX Runner Elapsed Time and ONNX Runner AVG Elapsed Time fields (note that the values are in microseconds).</p> <p></p>"}]}